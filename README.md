# site-scanning-analysis

Analysis reports for the Site Scanning program

## Important Links

- [Program Website](https://digital.gov/site-scanning)
- Analysis Reports: [Snapshot - Primary](https://github.com/GSA/site-scanning-analysis/blob/main/reports/snapshot-primary.csv); [Snapshot - All](https://github.com/GSA/site-scanning-analysis/blob/main/reports/snapshot-all.csv); [Federal Website Index](https://github.com/GSA/site-scanning-analysis/blob/main/reports/target-url-list.csv); [Federal Website Index Creation Process](https://github.com/GSA/federal-website-index/blob/main/data/site-scanning-target-url-list-analysis.csv)
- [System Schedule - When ingests, reports, scans, etc. take place each week](https://github.com/GSA/site-scanning-documentation/blob/main/pages/schedule.md)
- [Snapshots at each stage of the target URL list generation process](https://github.com/GSA/federal-website-index/tree/main/data/snapshots#readme)
- [Debugging Guide](https://github.com/GSA/site-scanning-documentation/blob/main/pages/debugging-guide.md); [Quality Assurance Walkthrough](https://github.com/GSA/site-scanning-documentation/blob/main/about/project-management/quality-assurance-walkthrough.md)
- [Repository for storing one-off snapshots of scan data](https://github.com/GSA/site-scanning-snapshots)
- [Sample dataset that represents different edge cases](https://github.com/GSA/site-scanning-documentation/blob/main/data/Representative_Sample_Dataset.csv)
- [Snapshots that attempt to remove duplicative websites](https://github.com/GSA/site-scanning-analysis/tree/main/unique_website_list/results)
